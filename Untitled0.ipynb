{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsUHHfxClklsoJASUqsfHs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sominshim/MBTI-classification-from-online-text/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dMnPmbUnUgP",
        "outputId": "0def0402-78c5-407b-aec0-03e6729b421a"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7faPrAeY4td"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pum3wNf-nemm"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "data = pd.read_csv(\"/content/drive/My Drive/data/data_clean.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfqR2adE33vu",
        "outputId": "f737df95-6f76-41c1-a15f-c9a74c05f390"
      },
      "source": [
        "!pip install kss\r\n",
        "!pip install soynlp\r\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\r\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git\r\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/5f/4d0ebba2f20bbb83fa84dc32519df38d9d5bf0295a727c50b758f63d7d03/kss-2.4.0.1-py3-none-any.whl (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 30kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 40kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hInstalling collected packages: kss\n",
            "Successfully installed kss-2.4.0.1\n",
            "Collecting soynlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.0.0)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n",
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-2nbds9g0\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-2nbds9g0\n",
            "Collecting tensorflow==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/ce/e76c4e3d2c245f4f20eff1bf9cbcc602109448142881e1f946ba2d7327bb/tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.4) (2.4.3)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from pykospacing==0.4) (2.10.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (3.12.4)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.2.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (1.19.5)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (0.10.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0->pykospacing==0.4) (2.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.4.3->pykospacing==0.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.4.3->pykospacing==0.4) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow==2.4.0->pykospacing==0.4) (51.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (4.2.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->pykospacing==0.4) (0.4.8)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.4-cp36-none-any.whl size=2255638 sha256=92cc636551c7dbdc5a95c6b18c2aef7f43a303936d40ce8c24ed69f5991305f2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fqq6awcd/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba\n",
            "Successfully built pykospacing\n",
            "Installing collected packages: tensorflow, argparse, pykospacing\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed argparse-1.4.0 pykospacing-0.4 tensorflow-2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-rcu3xgbl\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-rcu3xgbl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp36-none-any.whl size=4854 sha256=a47b4ee45837f1e0917a91535f978b11e3ff4ecec5ce6d0ea5204bde01ca77a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eg1je_7b/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, colorama, tweepy, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz70BauN3e5O",
        "outputId": "8dbb2ab1-253b-42e8-cbe4-42ae85cd3ef7"
      },
      "source": [
        "import konlpy\r\n",
        "from konlpy.tag import Kkma, Okt, Komoran\r\n",
        "from pprint import pprint\r\n",
        "\r\n",
        "print(konlpy.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4TZ27AC4S5N"
      },
      "source": [
        "sent = '이건 테스트 문장입니다'\r\n",
        "kkma = Kkma()\r\n",
        "twitter = Okt()\r\n",
        "komoran = Komoran()\r\n",
        "\r\n",
        "taggers = [kkma, twitter, komoran]\r\n",
        "names = 'kkma twitter komoran'.split()\r\n",
        "for tagger in taggers:\r\n",
        "    poses = tagger.pos(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1usSCrb4XqY",
        "outputId": "241411a6-3dcd-446a-8e05-fbd637b2ba2d"
      },
      "source": [
        "%%time\r\n",
        "komoran.pos(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.47 ms, sys: 1.05 ms, total: 8.52 ms\n",
            "Wall time: 5.15 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('이건', 'NNP'), ('테스트', 'NNP'), ('문장', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EC')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXjGfo_64cIw",
        "outputId": "36ce5551-e4be-4bed-8ae3-89291e501a11"
      },
      "source": [
        "komoran.nouns(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['이건', '테스트', '문장']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwMBa0R4fb7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "39Z8dwP_nrbS",
        "outputId": "e4905618-ea9e-41e6-eaeb-4a1b90b5cecb"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>clean_posts</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ESTP</td>\n",
              "      <td>최근 카페 질의응답 게시판 지속 등업 요구하다 글 올라오다 있다 엠헬 가입인사 코너...</td>\n",
              "      <td>1. 최근 카페의 질의응답 게시판에 지속적으로 등업을 요구하는 글이 올라오고 있습니...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>INFP</td>\n",
              "      <td>크 연타 주다 글 자신 마음 안 들다 늘 부족하다 것 같 절대 사랑하다 없 사람 글...</td>\n",
              "      <td>제게 큰 현타를 주었던 글이에요.제 자신이 마음에 안 들고,늘 부족한 것 같고,절대...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISFJ</td>\n",
              "      <td>유고슬라비아 남 슬 라브 국가 세르비아 슬로베니아 크로아티아 보스니아 북마케도니아 ...</td>\n",
              "      <td>유고슬라비아는 남슬라브 국가들(세르비아, 슬로베니아, 크로아티아, 보스니아, 북마케...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISTP</td>\n",
              "      <td>대 여자 키 크 나이 비하다 성숙하다 이미지 가지다 있다 잇 팁답다 차갑 도도 첫인...</td>\n",
              "      <td>10대 여자고 키도 크고 나이에 비해 성숙한 이미지를 가지고 있어요. 잇팁답게 차갑...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>요즘 끌리다 남자 있다 이다 거 같 인줄 알다 상황 따르다 행동 변경 잘 하 고백하...</td>\n",
              "      <td>제가 요즘 끌리는 남자가있는데 esfp인거같아요esfj인줄 알았는데 상황에따라 행동...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20747</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>카페서 글 보다 덧글 달다 글 쓰다 반면 옆 친구 축구 보다 뉴스 보다 있다 ㅎ ㅎ...</td>\n",
              "      <td>나는 이 카페서 글보고 덧글달고 글쓰는 반면옆의 친구(ISTJ)는 축구보고 뉴스보고...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20748</th>\n",
              "      <td>ENFJ</td>\n",
              "      <td>년 넘다 친구 있다 친구 성격 추측하다 보다 때 친구 그런데 검사 시키다 보다 거 ...</td>\n",
              "      <td>10년넘은 친구가 있는데 그친구의 성격으로 제가 추측해봤을 때 그 친구는 E*FP였...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20749</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>구성 짓다 음 가르라다 놓다 날 목 마르다 친구 녀석 물 달다 하다 그러다 녀석 자...</td>\n",
              "      <td>구성지음, 갈라놓음. istj가 아닐까요.어느날 제가 목이 말라서 친구녀석에게 물좀...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20750</th>\n",
              "      <td>ISTJ</td>\n",
              "      <td>유형하다 질문 있다 하다 대부분 남자 잘 맞다 거 같 여자 유형 어떻 되다 질문 올...</td>\n",
              "      <td>이런 유형의 비슷한 질문이 있기는 했지만 대부분 ISTJ 남자와 잘맞을 거 같은 여...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20751</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>학교 말 듣다 숙제 백상 예술 대상 조사하다 가다 하다 어떻 하다 하다 잘 모르다 ...</td>\n",
              "      <td>학교 말듣 숙제로 백상예술대상을 조사해 가야 하는데 어떻게 해야 할지 잘 모르겠어요...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20752 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       type  ...                                              posts\n",
              "0      ESTP  ...  1. 최근 카페의 질의응답 게시판에 지속적으로 등업을 요구하는 글이 올라오고 있습니...\n",
              "1      INFP  ...  제게 큰 현타를 주었던 글이에요.제 자신이 마음에 안 들고,늘 부족한 것 같고,절대...\n",
              "2      ISFJ  ...  유고슬라비아는 남슬라브 국가들(세르비아, 슬로베니아, 크로아티아, 보스니아, 북마케...\n",
              "3      ISTP  ...  10대 여자고 키도 크고 나이에 비해 성숙한 이미지를 가지고 있어요. 잇팁답게 차갑...\n",
              "4      ISFP  ...  제가 요즘 끌리는 남자가있는데 esfp인거같아요esfj인줄 알았는데 상황에따라 행동...\n",
              "...     ...  ...                                                ...\n",
              "20747  INFJ  ...  나는 이 카페서 글보고 덧글달고 글쓰는 반면옆의 친구(ISTJ)는 축구보고 뉴스보고...\n",
              "20748  ENFJ  ...  10년넘은 친구가 있는데 그친구의 성격으로 제가 추측해봤을 때 그 친구는 E*FP였...\n",
              "20749  INFJ  ...  구성지음, 갈라놓음. istj가 아닐까요.어느날 제가 목이 말라서 친구녀석에게 물좀...\n",
              "20750  ISTJ  ...  이런 유형의 비슷한 질문이 있기는 했지만 대부분 ISTJ 남자와 잘맞을 거 같은 여...\n",
              "20751  ISFP  ...  학교 말듣 숙제로 백상예술대상을 조사해 가야 하는데 어떻게 해야 할지 잘 모르겠어요...\n",
              "\n",
              "[20752 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joGSw5Hp6pkG"
      },
      "source": [
        "\r\n",
        "train_data=X[:160000]\r\n",
        "test_data=X[160000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hAskuo6pf3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqjtpnNK6pXx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw6fQtFi6pKE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAb9AM_Fcb23"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from wordcloud import WordCloud\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7yMJyIOcb0A"
      },
      "source": [
        "import re\r\n",
        "import json\r\n",
        "from konlpy.tag import Okt\r\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnNAQ825cbgD"
      },
      "source": [
        "def preprocessing(review, okt, remove_stopwords = False, stop_words = []):\r\n",
        "    # 함수의 인자는 다음과 같다.\r\n",
        "    # review : 전처리할 텍스트\r\n",
        "    # okt : okt 객체를 반복적으로 생성하지 않고 미리 생성후 인자로 받는다.\r\n",
        "    # remove_stopword : 불용어를 제거할지 선택 기본값은 False\r\n",
        "    # stop_word : 불용어 사전은 사용자가 직접 입력해야함 기본값은 비어있는 리스트\r\n",
        "    \r\n",
        "    # 1. 한글 및 공백을 제외한 문자 모두 제거. + 영어 소문자, 대문자, 숫자도 제외\r\n",
        "    # 일단 OCR 결과의 원형을 학습시키기 위해 정규표현식을 사용하지 않고 학습시켜보겠습니다.\r\n",
        "    review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9\\\\s]\", \"\",  review)\r\n",
        "    #review_text = re.sub(\" \", \"\",  review)\r\n",
        "    \r\n",
        "    # 2. okt 객체를 활용해서 형태소 단위로 나눈다.\r\n",
        "    word_review = okt.morphs(review_text, stem=True)\r\n",
        "    \r\n",
        "    if remove_stopwords:\r\n",
        "        \r\n",
        "        # 불용어 제거(선택적)\r\n",
        "        word_review = [token for token in word_review if not token in stop_words]\r\n",
        "        \r\n",
        "   \r\n",
        "    return word_review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8FpZB1hdPdH"
      },
      "source": [
        "!JAVA_HOME='C:\\Program Files\\Java\\jdk-15'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "azeOwm0dcbrg",
        "outputId": "396177cd-d107-46ec-ed7f-582f8f578a44"
      },
      "source": [
        "stop_words = ['은', '는', '이', '가', '하', '아', '것', '들','의', '있', '되', '수', '보', \r\n",
        "              '주', '등', '한', '(', ')', '/', '*', '=', 'E', '|', '-', '.', ',', 'II', 'لالالالا', \r\n",
        "              '|||||||||', 'iii', '|||', '. ', '.', '\"', ' )', '[', ']']\r\n",
        "\r\n",
        "from konlpy.tag import Kkma\r\n",
        "\r\n",
        "clean_train_review = []\r\n",
        "tokenizer = Kkma()\r\n",
        "for review in tqdm(train_data['document']):\r\n",
        "    # 비어있는 데이터에서 멈추지 않도록 string인 경우만 진행\r\n",
        "    if type(review) == str:\r\n",
        "        clean_train_review.append(preprocessing(review, okt, remove_stopwords = True, stop_words=stop_words))\r\n",
        "    else:\r\n",
        "        clean_train_review.append([])  #string이 아니면 비어있는 값 추가"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2334ce395d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclean_train_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKkma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 비어있는 데이터에서 멈추지 않도록 string인 경우만 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvmpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misJVMStarted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mjvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvmpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mkkmaJavaPackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJPackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kr.lucypark.kkma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/konlpy/jvm.py\u001b[0m in \u001b[0;36minit_jvm\u001b[0;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                 \u001b[0;34m'-Dfile.encoding=UTF8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                 \u001b[0;34m'-ea'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-Xmx{}m'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_heap_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                 convertStrings=True)\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please specify the JVM path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: startJVM() got an unexpected keyword argument 'convertStrings'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "m-n4u0-3-IPD",
        "outputId": "ddd28685-bce4-40df-9dc8-e18b8a35f62b"
      },
      "source": [
        "data['posts'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"1. 최근 카페의 질의응답 게시판에 지속적으로 등업을 요구하는 글이 올라오고 있습니다. 엠헬은 가입인사 코너에 3개의 댓글을 달면 별도의 요청글 없이 자동적으로 등업이 되는 시스템입니다.규정을 읽지 않고 올라오는 무조건적인 등업 요청글에 대해 스탭은 별도의 안내를 드리지 않겠습니다. 규정 숙지하시고 즐거운 엠헬 활동하시길 바라겠습니다. 2. 신고 게시글에 잇따른 동성애 및 종교에 관련한 내용이 올라오고 있습니다.종교 및 성지향성에 대한 개인의 신념은 모두 존중받아 마땅하나 '심리' 카페인 엠헬에서 이에 대한 논쟁이 지나치게 깊게 이뤄지는 것은 카페 취지에 어긋납니다. 카페 내의 질서와 평화를 위해 앞으로 자신의 인적 소개용으로 간단하게 언급되는게 아닌 논쟁을 위한 종교, 성지향성 글은 발견되면 무통보 삭제하도록 하겠습니다. 읽어주셔서 감사합니다.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzKXOLIhEMYX",
        "outputId": "fe569e1a-4283-4336-8cf9-b882d02468d5"
      },
      "source": [
        "!pip install open-korean-text-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting open-korean-text-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/d6/23899a6bb5aa10574d199b606fcf7125522d8839f28baf2ec146f74403af/open-korean-text-python-1.0.0.tar.gz (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 6.5MB/s \n",
            "\u001b[?25hCollecting Jpype1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from Jpype1->open-korean-text-python) (3.7.4.3)\n",
            "Building wheels for collected packages: open-korean-text-python\n",
            "  Building wheel for open-korean-text-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for open-korean-text-python: filename=open_korean_text_python-1.0.0-cp36-none-any.whl size=6649703 sha256=50fae2b0849fe3978441dcc48c46a87cb4d4a0251b883eb422beb2fc534f0cbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/9d/72/7240b5965225f181965650d80849d38b2c9fa3deb049b29d09\n",
            "Successfully built open-korean-text-python\n",
            "Installing collected packages: Jpype1, open-korean-text-python\n",
            "Successfully installed Jpype1-1.2.1 open-korean-text-python-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoRMu_MgEaOV"
      },
      "source": [
        "import pytest\r\n",
        "import openkoreantext\r\n",
        "from openkoreantext import add_words_to_dictionary, normalize, morphs, nouns, phrases, pos, sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99T0jnjaEP7i",
        "outputId": "c49fe25a-7b17-465c-81da-c88be51ce412"
      },
      "source": [
        "openkoreantext.normalize(data['posts'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. 최근 카페의 질의응답 게시판에 지속적으로 등업을 요구하는 글이 올라오고 있습니다. 엠헬은 가입인사 코너에 3개의 댓글을 달면 별도의 요청글 없이 자동적으로 등업이 되는 시스템입니다.규정을 읽지 않고 올라오는 무조건적인 등업 요청글에 대해 스탭은 별도의 안내를 드리지 않겠습니다. 규정 숙지하시고 즐거운 엠헬 활동하시길 바라겠습니다. 2. 신고 게시글에 잇따른 동성애 및 종교에 관련한 내용이 올라오고 있습니다.종교 및 성지향성에 대한 개인의 신념은 모두 존중받아 마땅하나 '심리' 카페인 엠헬에서 이에 대한 논쟁이 지나치게 깊게 이뤄지는 것은 카페 취지에 어긋납니다. 카페 내의 질서와 평화를 위해 앞으로 자신의 인적 소개용으로 간단하게 언급되는게 아닌 논쟁을 위한 종교, 성지향성 글은 발견되면 무통보 삭제하도록 하겠습니다. 읽어주셔서 감사합니다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "VFOn61KGE9V-",
        "outputId": "a0ad0eb4-f878-4540-d945-7177441b43bb"
      },
      "source": [
        "data['posts'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"제게 큰 현타를 주었던 글이에요.제 자신이 마음에 안 들고,늘 부족한 것 같고,절대 사랑할 수 없는 사람이 저였는데,이 글을 읽고 '아하' 무릎을 쳤어요.10대 후반까지도진짜 제가 누구인지 모를 때주변에서 제게 주었던 평가들로나란 사람을 규정해 버린 거에요.'이기적이다, 못됐다, 맨날 실수만 해,동생보다도 못하니?다른 애들은 이런 것도 하더라..'그건 진짜 제가 아닌데 말이죠.부모님, 주변 사람들도저를 잘 모르고 한 말들이잖아요.그리고, 그 때의 저는 아이였잖아요.배워가야 하는 때의 저에게는 가혹한 잣대의 말보다격려와 인정의 말이 더 필요했어요.그래서, 우리는 삶의 한 중간에는진짜 나를 돌아보는 시간이 있어야 해요.다른 사람들의 평가와 시각으로둘러싸인 내가 아니라,번데기를 뚫고 나온진짜 나의 날개를 바라볼 시각을갖춰야 해요.제대로 바라보고,길을 찾아갈 수 있어요.상담실에 처음 오실 때는무기력하고, 지치고, 불안정한 모습이세요.상담을 통해 마음이 가벼워지고,방향키를 확실히 잡으면서일상의 파도에도 중심을 잡고자신있게 나아가신답니다.히말라야 산 등반에 꼭 필요한 셰파처럼마음여행의 전문가인 상담사가든든한 동행자로 함께 합니다^^*상담 안내*대면상담과 온라인 줌 상담모두 가능합니다.유료상담은 회기당 50분이며,단회기(1~3)에 끝나거나장기상담(5회기 이상)으로 진행됩니다.불안, 우울감, 무기력, 대인관계 문제,가족 문제, 이별,\\xa0번 아웃 등의 주제를 나눕니다.Here & Now에서감정, 욕구, 감각 등을\\xa0알아차리며,내면의 미해결과제를 치유하는게슈탈트 심리상담,MBTI 선호유형과 현재의 심리상태를 탐색하는PTS(Psychological Type Searching) 등을활용합니다.출처: 수석매니저 카가님 블로그저의 개인 랜딩페이지 소개입니다.https://c11.kr/gohm카페 내 강사프로필 소개글입니다.https://cafe.naver.com/mbticafe/304166유료 상담 신청 및 문의는카카오채널로 받습니다.(엠헬카페 내 규칙과 동일하게 적용되며,장난, 단순 호기심은 정중히 사양합니다.)https://pf.kakao.com/_dhktxb자신의 어려움을 진지하게 돌보고 싶은 분들을기다리겠습니다.긴 글, 읽어주셔서 감사합니다^^\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urnfdq2CFB24",
        "outputId": "109b5dcd-28d9-4046-ba65-2343af97966c"
      },
      "source": [
        "openkoreantext.normalize('안녕하세욬ㅋㅋㅋㅋ') # 안녕하세요ㅋㅋㅋ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요ㅋㅋㅋ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "2bNmCGWH-5lO",
        "outputId": "c2677543-9a19-4f95-b955-de58da69317b"
      },
      "source": [
        "from .document import Document\r\n",
        "import re\r\n",
        "from soynlp.normalizer import repeat_normalize\r\n",
        "import logging\r\n",
        "\r\n",
        "logger = logging.getLogger(__name__)\r\n",
        "\r\n",
        "# https://github.com/YongWookHa/kor-text-preprocess/blob/master/src/clean.py\r\n",
        "# https://github.com/monologg/KoELECTRA/blob/master/docs/preprocessing.md\r\n",
        "\r\n",
        "class PreProcessing(Document):\r\n",
        "    def __init__(self, in_path, out_path, min_length=7):\r\n",
        "        Document.__init__(self,in_path,out_path=out_path)\r\n",
        "        self.min_length = min_length\r\n",
        "        self.sub1 = re.compile(r'[^ .,?!/@$%~％·∼()\\x00-\\x7F가-힣]+') # 한글/영어 및 띄어쓰기, 특수기호 일부를 제외한 모든 글자\r\n",
        "        self.sub2 = re.compile(r'[\\s]+')  # white space duplicate\r\n",
        "        self.sub3 = re.compile(r' ?[\\.]+')  # full stop duplicate\r\n",
        "        self.sub4 = re.compile(r' ?[,]+ ?( ?,)+ ?')  # comma duplicate\r\n",
        "        self.spe_char1 = re.compile(r'[·\"]') # special characters replace with \\s\r\n",
        "        self.spe_char2 = re.compile(r' ?[<>\\\\*] ?') # special characters replace with ''\r\n",
        "\r\n",
        "    def apply(self):\r\n",
        "        self.remove_en_sent()\r\n",
        "        self.clean()\r\n",
        "        self.lines = list(dict.fromkeys(self.lines))\r\n",
        "        self.remove_parantheses()\r\n",
        "        self.remove_list()\r\n",
        "        self.remove_news_brackets()\r\n",
        "        self.remove_links()\r\n",
        "        self.remove_unmatched_items()\r\n",
        "        self.remove_repeat()\r\n",
        "        self.lines = [l.strip('-').strip('=').strip('/').strip() for l in self.lines if len(l) > self.min_length]\r\n",
        "        logging.info(f'8: {len(self.lines):,}')\r\n",
        "        self.write_lines()\r\n",
        "\r\n",
        "    def clean(self):\r\n",
        "        new_lines=[]\r\n",
        "        for line in self.lines:\r\n",
        "            cleaned = self.sub1.sub('', line.strip())\r\n",
        "            cleaned = self.spe_char1.sub(' ',cleaned)\r\n",
        "            cleaned = self.spe_char2.sub('',cleaned)\r\n",
        "            cleaned = self.sub2.sub(' ', cleaned)\r\n",
        "            cleaned = self.sub3.sub('.', cleaned)\r\n",
        "            cleaned = self.sub4.sub(', ', cleaned)\r\n",
        "            if len(cleaned) > self.min_length:\r\n",
        "                new_lines.append(cleaned.strip())\r\n",
        "        self.lines = self.split_by_punct(new_lines)\r\n",
        "\r\n",
        "    def remove_en_sent(self):\r\n",
        "        KOR = re.compile('[가-힣]')\r\n",
        "        self.lines = [l for l in self.lines if KOR.search(l)]\r\n",
        "    \r\n",
        "    def remove_list(self):\r\n",
        "        LIST = re.compile(r'.*[XVI|0-9][\\.|\\)]')\r\n",
        "        self.lines = [l for l in self.lines if not LIST.match(l)]\r\n",
        "    \r\n",
        "    def remove_parantheses(self):\r\n",
        "        PARANTHESES = re.compile(r\"\\([^()]*\\)\")\r\n",
        "        self.lines = [PARANTHESES.sub('',l) for l in self.lines]    \r\n",
        "\r\n",
        "    def remove_news_brackets(self):\r\n",
        "        NEWS_BRACKETS = re.compile(r\"(\\[.+기자\\])\")\r\n",
        "        self.lines = [NEWS_BRACKETS.sub('',l) for l in self.lines]  \r\n",
        "\r\n",
        "    def remove_links(self):\r\n",
        "        LINKS = re.compile(r\"(www.|html|http|.com|.co|.kr)\")\r\n",
        "        self.lines = [l for l in self.lines if not LINKS.search(l)] \r\n",
        "    \r\n",
        "    def remove_unmatched_items(self):\r\n",
        "        UNMATCHED_ITEMS = re.compile(r'[\\[\\]\\(\\)] ?')\r\n",
        "        self.lines = [UNMATCHED_ITEMS.sub('',l) for l in self.lines]  \r\n",
        "    \r\n",
        "    def remove_repeat(self):\r\n",
        "        self.lines = [repeat_normalize(l, num_repeats=2) for l in self.lines]\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-558b014d2fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msoynlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrepeat_normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.document'; '__main__' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "NAyVOflnGT1Z",
        "outputId": "554795b0-4ab5-4895-bc0d-399f516a9950"
      },
      "source": [
        "from .utils import Refine\r\n",
        "from tqdm import tqdm\r\n",
        "import re\r\n",
        "from os.path import normpath\r\n",
        "\r\n",
        "class Clean_kor(Refine):\r\n",
        "    def __init__(self, args):\r\n",
        "        super().__init__()\r\n",
        "        self.args = [normpath(args.input), normpath(args.output), args.encoding]\r\n",
        "\r\n",
        "        self.sub1 = re.compile('[^ .?!/@$%~|0-9|ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기, 특수기호 일부를 제외한 모든 글자\r\n",
        "        self.sub2 = re.compile('[\\s]+')  # white space duplicate\r\n",
        "        self.sub3 = re.compile('[\\.]+')  # full stop duplicate\r\n",
        "        \r\n",
        "    def apply(self):\r\n",
        "        self.clean(*self.args)\r\n",
        "\r\n",
        "    def clean(self, inp_path, out_path, encoding='utf8'):\r\n",
        "        \"\"\"\r\n",
        "        This function will clean the text.\r\n",
        "        It will remain only korean characters, numbers, and some special symbols.\r\n",
        "        \"\"\"\r\n",
        "        with open(out_path, \"w\", encoding=encoding) as out:\r\n",
        "            num_line = sum(1 for line in open(inp_path, \"r\", encoding=encoding))\r\n",
        "            lines = super().readline(inp_path, encoding)\r\n",
        "            for line in tqdm(lines, desc=\"cleaning\", total=num_line):\r\n",
        "                if not line:\r\n",
        "                    break\r\n",
        "                else:\r\n",
        "                    cleaned = self.sub1.sub('', line.strip()) \r\n",
        "                    cleaned = self.sub2.sub(' ', cleaned)\r\n",
        "                    cleaned = self.sub3.sub('.', cleaned) \r\n",
        "                    if not cleaned:\r\n",
        "                        continue\r\n",
        "                    out.write(cleaned+'\\n')\r\n",
        "        print(\"process done, saved at {}\".format(out_path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-abff6a353e44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRefine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.utils'; '__main__' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ottQ5HXzn7Ad",
        "outputId": "59eeba6d-3261-40c4-947d-3253a4b85147"
      },
      "source": [
        "data['type'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ESTP', 'INFP', 'ISFJ', 'ISTP', 'ISFP', 'ENTJ', 'ENTP', 'INTJ',\n",
              "       'ISTJ', 'ENFP', 'ENFJ', 'ESFJ', 'INTP', 'ESFP', 'ESTJ', 'INFJ'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKnvQRLanRXP"
      },
      "source": [
        "import random as rd\r\n",
        "import csv\r\n",
        "\r\n",
        "\r\n",
        "rd.seed(2020)\r\n",
        "\r\n",
        "LABEL = {\r\n",
        "    'ESTP':0, 'INFP':1, 'ISFJ':, 'ISTP':, 'ISFP':, 'ENTJ':, 'ENTP':, 'INTJ':,\r\n",
        "       'ISTJ':, 'ENFP':, 'ENFJ':, 'ESFJ':, 'INTP':, 'ESFP':, 'ESTJ':, 'INFJ':\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "def read_txt(filename):\r\n",
        "    dataset = []\r\n",
        "    with open(filename, 'r', encoding=\"utf-8\", newline='') as f:\r\n",
        "        for line in f.readlines()[1:]:\r\n",
        "            split_data = line.rstrip(\"\\n\").split(\"\\t\")\r\n",
        "            doc = split_data[0] + \" [SEP] \" + split_data[1]\r\n",
        "            label = int(LABEL[split_data[2]])\r\n",
        "\r\n",
        "            dataset.append((label, doc))\r\n",
        "\r\n",
        "        print(\"Number of data in {} : {} \".format(filename, len(dataset)))\r\n",
        "\r\n",
        "    return dataset\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}